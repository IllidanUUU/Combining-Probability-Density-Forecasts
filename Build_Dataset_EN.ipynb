{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used for building the datasets for training based on ISONE Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sheetName = 'NEMASSBOST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for NaN in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2013 Data contains NaN: False\n",
      "\n",
      "2014 Data contains NaN: False\n",
      "\n",
      "2015 Data contains NaN: False\n",
      "\n",
      "2016 Data contains NaN: False\n"
     ]
    }
   ],
   "source": [
    "df_2016 = pd.read_excel('ISONE Load Data/smd_hourly.xls', sheet_name = sheetName, usecols = [0, 1, 3])\n",
    "df_2015 = pd.read_excel('ISONE Load Data/smd_hourly(1).xls', sheet_name = sheetName, usecols = [0, 1, 3])\n",
    "df_2014 = pd.read_excel('ISONE Load Data/2014_smd_hourly.xls', sheet_name = sheetName, usecols = [0, 1, 3])\n",
    "df_2013 = pd.read_excel('ISONE Load Data/2013_smd_hourly.xls', sheet_name = sheetName, usecols = [0, 1, 3])\n",
    "\n",
    "print('\\n2013 Data contains NaN:', np.any(np.isnan(df_2013.iloc[:,1:].values)))\n",
    "print('\\n2014 Data contains NaN:', np.any(np.isnan(df_2014.iloc[:,1:].values)))\n",
    "print('\\n2015 Data contains NaN:', np.any(np.isnan(df_2015.iloc[:,1:].values)))\n",
    "print('\\n2016 Data contains NaN:', np.any(np.isnan(df_2016.iloc[:,1:].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2016.columns = df_2015.columns\n",
    "df = pd.concat([df_2013, df_2014, df_2015, df_2016]).reset_index(drop = True)\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
    "df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
    "df['Weekday'] = pd.DatetimeIndex(df['Date']).weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_prev_info(hours_ahead, demand = df['DEMAND']):\n",
    "    return demand.shift(hours_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features and labels, then write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ONE DAY BEFORE\n",
    "df['D1'] = add_prev_info(24)\n",
    "df['D2'] = add_prev_info(25)\n",
    "df['D3'] = add_prev_info(26)\n",
    "df['D4'] = add_prev_info(27)\n",
    "df['D5'] = add_prev_info(28)\n",
    "# TWO DAYS BEFORE\n",
    "df['DD1'] = add_prev_info(46)\n",
    "df['DD2'] = add_prev_info(47)\n",
    "df['DD3'] = add_prev_info(48)\n",
    "df['DD4'] = add_prev_info(49)\n",
    "df['DD5'] = add_prev_info(50)\n",
    "# ONE WEEK BEFORE\n",
    "df['W1'] = add_prev_info(166)\n",
    "df['W2'] = add_prev_info(167)\n",
    "df['W3'] = add_prev_info(168)\n",
    "df['W4'] = add_prev_info(169)\n",
    "df['W5'] = add_prev_info(170)\n",
    "# ONE MONTH BEFORE\n",
    "df['M1'] = add_prev_info(718)\n",
    "df['M2'] = add_prev_info(719)\n",
    "df['M3'] = add_prev_info(720)\n",
    "df['M4'] = add_prev_info(721)\n",
    "df['M5'] = add_prev_info(722)\n",
    "# ONE YEAR BEFORE\n",
    "df['Y1'] = add_prev_info(8758)\n",
    "df['Y2'] = add_prev_info(8759)\n",
    "df['Y3'] = add_prev_info(8760)\n",
    "df['Y4'] = add_prev_info(8761)\n",
    "df['Y5'] = add_prev_info(8762)\n",
    "# SOME DAYS BEFORE\n",
    "df['1D'] = add_prev_info(24)\n",
    "df['2D'] = add_prev_info(48)\n",
    "df['3D'] = add_prev_info(72)\n",
    "df['4D'] = add_prev_info(96)\n",
    "df['5D'] = add_prev_info(120)\n",
    "df['6D'] = add_prev_info(144)\n",
    "df['7D'] = add_prev_info(168)\n",
    "\n",
    "df['Weekend?'] = (df['Weekday']>4).astype(int)\n",
    "df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "df = df[df['Year']>2013].drop(columns=['Year'])\n",
    "df = df.drop([8760,8761])\n",
    "\n",
    "for col in [x for x in df.columns.tolist() if x not in ['Date', 'Weekday', 'Weekend?']]:\n",
    "    df = df.loc[df[col]!=0]\n",
    "    \n",
    "df = df.reset_index(drop = True)\n",
    "df.to_csv('Data/'+sheetName+'_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train/dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regionName = sheetName\n",
    "csvName = 'Data/'+ regionName + '_data.csv'\n",
    "df = pd.read_csv(csvName)\n",
    "df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "df_train = df[df['Year'] == 2014].drop(columns=['Year'])\n",
    "df_dev = df[df['Year'] == 2015].drop(columns=['Year'])\n",
    "df_dev = df_dev[df_dev['Month'] < 3]\n",
    "df_dev = df_dev[:840]\n",
    "df_dev2 = df[8731+840:8731+840+840]\n",
    "df_test = df[8731+840*2:8731+840*3]\n",
    "df_train.to_csv('Data/'+regionName+'_train.csv', index = False)\n",
    "df_dev.to_csv('Data/'+regionName+'_dev.csv', index = False)\n",
    "df_dev2.to_csv('Data/'+regionName+'_dev2.csv', index = False)\n",
    "df_test.to_csv('Data/'+regionName+'_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
